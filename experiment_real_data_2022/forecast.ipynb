{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sys import argv\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from particle_filter import particlefilter\n",
    "from pmcmc import particlemcmc\n",
    "from math_utils import nbinom_logpmf,norm_logpmf,beta_logpdf,uniform_logpdf,poisson_logpmf\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./AZ_FLU_HOSPITALIZATIONS.csv',index_col = False).to_numpy().T[1]\n",
    "data = np.expand_dims(data[:200],0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIRH_model(particles,observations,t,dt,model_params,rng):\n",
    "    '''Definition of SEIR model as described in Calvetti's paper. Difference \n",
    "    is the use of Tau leaping to introduce stochasticity into the system and continuous log-normal OU process definition for beta.'''\n",
    "    hosp,D,mu,sig = model_params\n",
    "\n",
    "    gamma = 1/1000\n",
    "    L = 0.\n",
    "    lam = 1/35\n",
    "    sig_state = 0.005\n",
    "\n",
    "    A = np.exp(-lam * dt)\n",
    "    M = mu * (np.exp(-lam * dt) - 1)\n",
    "    C = sig * np.sqrt(1 - np.exp(-2 * lam * dt))\n",
    "\n",
    "    for index in range(particles.shape[0]):\n",
    "\n",
    "        new_S = ((L * particles[index,3,t]) * dt) \n",
    "        new_I = ((particles[index,4,t] * (particles[index,0,t] * particles[index,1,t])/np.sum(particles[index,:,t])) * dt)\n",
    "        new_IH = ((D * gamma * particles[index,1,t]) * dt)\n",
    "        new_HR = ((hosp * particles[index,2,t]) * dt)\n",
    "        new_IR = ((D *(1 - gamma) * particles[index,1,t]) * dt)\n",
    "\n",
    "        particles[index,0,t] = np.maximum(0.,particles[index,0,t] + new_S - new_I + sig_state/np.sum(particles[index,:,t]) * particles[index,0,t] * rng.normal(0,np.sqrt(dt)))\n",
    "        particles[index,1,t] = np.maximum(0.,particles[index,1,t] + new_I - (new_IH + new_IR) + sig_state * particles[index,1,t] * rng.normal(0,np.sqrt(dt)))\n",
    "        particles[index,2,t] = np.maximum(0.,particles[index,2,t] + new_IH - new_HR + sig_state * particles[index,2,t] * rng.normal(0,np.sqrt(dt)))\n",
    "        particles[index,3,t] = np.maximum(0.,particles[index,3,t] + new_HR + new_IR - new_S + sig_state * particles[index,3,t] * rng.normal(0,np.sqrt(dt)))\n",
    "\n",
    "        particles[index,4,t] = np.exp(A * np.log(particles[index,4,t]) - M + C * rng.standard_normal())\n",
    "\n",
    "        observations[index,0,t] = particles[index,2,t]\n",
    "\n",
    "    return particles,observations\n",
    "\n",
    "def SIRH_Obs(data_point, particle_observations, model_params):\n",
    "    weights = poisson_logpmf(k = data_point,mu = particle_observations[:,0] + 0.005)\n",
    "    return weights\n",
    "\n",
    "def SIRH_init(num_particles, model_dim, rng):\n",
    "    particles_0 = np.zeros((num_particles,model_dim))\n",
    "    particles_0[:,0] = 7_329_000\n",
    "    I_init = rng.integers(10_000,200_000,size = (num_particles))\n",
    "    particles_0[:,0] -= I_init\n",
    "    particles_0[:,1] = I_init\n",
    "    particles_0[:,2] = 8\n",
    "    particles_0[:,3] = 0\n",
    "    particles_0[:,4] = rng.uniform(0.0,0.4, size = (num_particles,))\n",
    "    \n",
    "    return particles_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "param_names = ['hosp','D','mean_ou','sig']\n",
    "\n",
    "times = [70,80,90,100,110,120,130,140,150,160,170,180]\n",
    "\n",
    "for run in range(len(times)):\n",
    "    burn_in = 100_000\n",
    "    output = np.load(f'Results/PMCMC_Output_{run}.npz')\n",
    "\n",
    "    pf_params = {'num_particles':10_000, \n",
    "                      'dt':0.1,\n",
    "                      'model':SIRH_model,\n",
    "                      'observation_model':SIRH_Obs,\n",
    "                      'model_dim':5,\n",
    "                      'particle_initializer':SIRH_init,\n",
    "                      'forecast_time':times[run]\n",
    "                      }\n",
    "\n",
    "    par = np.mean((output['accepted_params'][:,burn_in:]),axis = 1)\n",
    "    \n",
    "    pf_output = particlefilter(data = data,\n",
    "        model_params= par,\n",
    "        pf_params = pf_params,\n",
    "        rng = np.random.default_rng(0),\n",
    "        req_jit=True\n",
    "        )\n",
    "\n",
    "    t_vec = np.arange(0,200,1)\n",
    "\n",
    "    with PdfPages(f'figures/figure_forecast_{times[run]}.pdf') as pdf:\n",
    "\n",
    "        fig,axs = plt.subplots(nrows = 2,ncols = 4,figsize = (20,10))\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[0,i].hist(output['accepted_params'][i,burn_in:],bins = 50)\n",
    "            axs[0,i].set_title(f\"{param_names[i]}, Mean: {np.round(np.mean(output['accepted_params'][i,burn_in:]),2)}, std: {np.round(np.std(output['accepted_params'][i,burn_in:]),2)}\")\n",
    "\n",
    "        axs[1,0].set_title(f\"{param_names[3]}, Mean: {np.round(np.mean(output['accepted_params'][3,burn_in:]),2)}, std: {np.round(np.std(output['accepted_params'][3,burn_in:]),2)}\")\n",
    "        axs[1,0].hist(output['accepted_params'][3,burn_in:],bins = 50)\n",
    "\n",
    "        axs[0,3].fill_between(t_vec,np.percentile(pf_output['particle_distribution'][:, 4, :].T, 12.5, axis=1),\n",
    "                              np.percentile(pf_output['particle_distribution'][:, 4, :].T, 87.5, axis=1),\n",
    "                              alpha=0.5, color='steelblue')\n",
    "\n",
    "        axs[1,2].set_title('Log Likelihood')\n",
    "        axs[1,2].plot(output['Log_Likelihood'][burn_in:])\n",
    "\n",
    "        axs[1,3].set_title('Real Data')\n",
    "        axs[1,3].fill_between(t_vec,\n",
    "                                      np.percentile(pf_output['particle_observations'][:, 0, :].T, 12.5, axis=1),\n",
    "                                      np.percentile(pf_output['particle_observations'][:, 0, :].T, 87.5, axis=1),\n",
    "                                      alpha=0.5, color='steelblue')\n",
    "        \n",
    "        axs[1,3].plot(data.T,'--',color = 'black')\n",
    "\n",
    "        # Save the current figure to the PDF\n",
    "        pdf.savefig(fig)  # Save the figure to the PDF\n",
    "        plt.close(fig)    # Close the figure to free up memory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
